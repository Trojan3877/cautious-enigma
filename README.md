# ğŸ›¡ï¸ AI-Powered Threat Detection System

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-Production%20API-009688?logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Ready-0db7ed?logo=docker)
![Kubernetes](https://img.shields.io/badge/Kubernetes-Deployable-326ce5?logo=kubernetes)
![Helm](https://img.shields.io/badge/Helm-Charts-0f1689?logo=helm)
![Terraform](https://img.shields.io/badge/Terraform-IaC-7B42BC?logo=terraform)
![MLflow](https://img.shields.io/badge/Model%20Registry-Custom-green?logo=mlflow)
![CI/CD](https://img.shields.io/badge/GitHub%20Actions-CI%2FCD-black?logo=githubactions)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Status-Active-success)



## ğŸš¨ Overview
Cautious Enigma is an enterprise-grade ML system designed to classify vehicle safety risk using structured sensor data.
The project includes:

Full L6-level ML architecture

Production inference API built with FastAPI

Model Registry with versioning & SHA256 fingerprints

Preprocessing Pipeline (training + inference consistency)

Training Orchestrator (Airflow/Kubeflow ready)

Batch & real-time inference pipelines

Kubernetes-ready deployment stack (Docker + Helm + Terraform)

CI/CD compatible

## ğŸ”§ Features
- Log ingestion and preprocessing
- Feature engineering for anomaly detection
- Isolation Forest-based threat classification
- Real-time alerting via console and webhook
- Configurable pipeline with modular components
- Ready for CI/CD and containerization

## ğŸ§  Technologies
- Python 3.9+
- Scikit-learn
- Pandas, NumPy
- Flask (optional API)
- Joblib
- Docker (optional)
- GitHub Actions (optional CI)

## ğŸ“ Project Structure
cautious-enigma/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py             # FastAPI server
â”‚   â””â”€â”€ server.py          # Uvicorn entrypoint
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.py  # Baseline ML classifier
â”‚   â”œâ”€â”€ inference.py       # Production inference engine
â”‚   â””â”€â”€ model_trainer.py   # Training orchestrator
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ preprocess.py      # Full preprocessing pipeline
â”‚   â”œâ”€â”€ train_pipeline.py  # End-to-end training DAG
â”‚   â””â”€â”€ inference_pipeline.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ model_registry.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â””â”€â”€ Dockerfile


                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚        config.yaml        â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚       Data Loader (utils/)         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Preprocess Pipeline     â”‚
                  â”‚ (training + inference)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚         Model Trainer           â”‚
                â”‚ (Pipeline + Evaluation + Save)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚     Model Registry         â”‚
                  â”‚ (v1, v2, v3 + SHA256 hash) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚       Inference Engine      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚             FastAPI              â”‚
                â”‚  /predict   /batch_predict       â”‚
                â”‚  /health    /ready    /live      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸš€ Getting Started

```bash
# Clone the repo
git clone https://github.com/yourusername/threat-detection-system.git
cd threat-detection-system

# Install dependencies
pip install -r requirements.txt

# Run the pipeline
python main.py
pytest tests/
docker build -t threat-detector .
docker run threat-detector
ALERT_WEBHOOK_URL=https://your-alert-endpoint.com/webhook
ALERT_EMAIL=security@yourdomain.com

## ğŸ“Š System Flowchart

```mermaid
flowchart TD
    A[Start: Log Data Ingestion] --> B[Preprocessing]
    B --> C[Feature Extraction]
    C --> D[Model Training / Loading]
    D --> E[Threat Detection]
    E --> F{Threats Found?}
    F -- Yes --> G[Send Alerts (Console/Webhook)]
    F -- No --> H[Log Normal Activity]
    G --> I[End]
    H --> I[End]


This flowchart shows:
- The modular pipeline from ingestion to alerting
- Decision logic for threat detection
- Clear separation of responsibilities

---

### ğŸ§± Next-Level Additions (Post-Flowchart)

Once the flowchart is in place, hereâ€™s what weâ€™ll add next:

#### ğŸ³ Dockerfile
Containerize the app for portability and deployment.

#### âš“ Helm Chart
Package your app for Kubernetes with customizable values.

#### ğŸ§° Ansible Playbook
Automate deployment across environments (e.g., dev, staging, prod).

#### â˜¸ï¸ Kubernetes Manifests
Define pods, services, and deployments for scalable orchestration.

#### â„ï¸ Snowflake Integration
Optional: Stream logs into Snowflake for long-term storage and analytics.

#### ğŸ§ª Advanced Files
- `tests/` with unit and integration tests
- `.env` with secrets (used via `python-dotenv`)
- `.github/workflows/ci.yml` for GitHub Actions
- `Makefile` for CLI automation
- `docs/architecture.md` for system design rationale

